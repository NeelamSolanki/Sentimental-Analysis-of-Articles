{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['blackassign0001',\n",
       "  'https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/\\n'],\n",
       " ['blackassign0002',\n",
       "  'https://insights.blackcoffer.com/rising-it-cities-and-their-impact-on-the-economy-environment-infrastructure-and-city-life-in-future/\\n'],\n",
       " ['blackassign0003',\n",
       "  'https://insights.blackcoffer.com/internet-demands-evolution-communication-impact-and-2035s-alternative-pathways/\\n'],\n",
       " ['blackassign0004',\n",
       "  'https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-in-upcoming-future/\\n'],\n",
       " ['blackassign0005',\n",
       "  'https://insights.blackcoffer.com/ott-platform-and-its-impact-on-the-entertainment-industry-in-future/\\n'],\n",
       " ['blackassign0006',\n",
       "  'https://insights.blackcoffer.com/the-rise-of-the-ott-platform-and-its-impact-on-the-entertainment-industry-by-2040/\\n'],\n",
       " ['blackassign0007',\n",
       "  'https://insights.blackcoffer.com/rise-of-cyber-crime-and-its-effects/\\n'],\n",
       " ['blackassign0008',\n",
       "  'https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035-2/\\n'],\n",
       " ['blackassign0009',\n",
       "  'https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040-2/\\n'],\n",
       " ['blackassign0010',\n",
       "  'https://insights.blackcoffer.com/rise-of-cybercrime-and-its-effect-by-the-year-2040/\\n'],\n",
       " ['blackassign0011',\n",
       "  'https://insights.blackcoffer.com/rise-of-internet-demand-and-its-impact-on-communications-and-alternatives-by-the-year-2035/\\n'],\n",
       " ['blackassign0012',\n",
       "  'https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-3-2/\\n'],\n",
       " ['blackassign0013',\n",
       "  'https://insights.blackcoffer.com/rise-of-e-health-and-its-impact-on-humans-by-the-year-2030/\\n'],\n",
       " ['blackassign0014',\n",
       "  'https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030-2/\\n'],\n",
       " ['blackassign0015',\n",
       "  'https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2/\\n'],\n",
       " ['blackassign0016',\n",
       "  'https://insights.blackcoffer.com/rise-of-telemedicine-and-its-impact-on-livelihood-by-2040-2-2/\\n'],\n",
       " ['blackassign0017',\n",
       "  'https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/\\n'],\n",
       " ['blackassign0018',\n",
       "  'https://insights.blackcoffer.com/rise-of-e-health-and-its-imapct-on-humans-by-the-year-2030/\\n'],\n",
       " ['blackassign0019',\n",
       "  'https://insights.blackcoffer.com/how-does-marketing-influence-businesses-and-consumers/\\n'],\n",
       " ['blackassign0020',\n",
       "  'https://insights.blackcoffer.com/how-advertisement-increase-your-market-value/\\n'],\n",
       " ['blackassign0021',\n",
       "  'https://insights.blackcoffer.com/negative-effects-of-marketing-on-society/\\n'],\n",
       " ['blackassign0022',\n",
       "  'https://insights.blackcoffer.com/how-advertisement-marketing-affects-business/\\n'],\n",
       " ['blackassign0023',\n",
       "  'https://insights.blackcoffer.com/rising-it-cities-will-impact-the-economy-environment-infrastructure-and-city-life-by-the-year-2035/\\n'],\n",
       " ['blackassign0024',\n",
       "  'https://insights.blackcoffer.com/rise-of-ott-platform-and-its-impact-on-entertainment-industry-by-the-year-2030/\\n'],\n",
       " ['blackassign0025',\n",
       "  'https://insights.blackcoffer.com/rise-of-electric-vehicles-and-its-impact-on-livelihood-by-2040/\\n'],\n",
       " ['blackassign0026',\n",
       "  'https://insights.blackcoffer.com/rise-of-electric-vehicle-and-its-impact-on-livelihood-by-the-year-2040/\\n'],\n",
       " ['blackassign0027',\n",
       "  'https://insights.blackcoffer.com/oil-prices-by-the-year-2040-and-how-it-will-impact-the-world-economy/\\n'],\n",
       " ['blackassign0028',\n",
       "  'https://insights.blackcoffer.com/an-outlook-of-healthcare-by-the-year-2040-and-how-it-will-impact-human-lives/\\n'],\n",
       " ['blackassign0029',\n",
       "  'https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\\n'],\n",
       " ['blackassign0030',\n",
       "  'https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\\n'],\n",
       " ['blackassign0031',\n",
       "  'https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\\n'],\n",
       " ['blackassign0032',\n",
       "  'https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\\n'],\n",
       " ['blackassign0033',\n",
       "  'https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\\n'],\n",
       " ['blackassign0034',\n",
       "  'https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\\n'],\n",
       " ['blackassign0035',\n",
       "  'https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\\n'],\n",
       " ['blackassign0036',\n",
       "  'https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\\n'],\n",
       " ['blackassign0037',\n",
       "  'https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\\n'],\n",
       " ['blackassign0038',\n",
       "  'https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\\n'],\n",
       " ['blackassign0039',\n",
       "  'https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/\\n'],\n",
       " ['blackassign0040',\n",
       "  'https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/\\n'],\n",
       " ['blackassign0041',\n",
       "  'https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/\\n'],\n",
       " ['blackassign0042',\n",
       "  'https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/\\n'],\n",
       " ['blackassign0043',\n",
       "  'https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/\\n'],\n",
       " ['blackassign0044',\n",
       "  'https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\\n'],\n",
       " ['blackassign0045',\n",
       "  'https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/\\n'],\n",
       " ['blackassign0046',\n",
       "  'https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/\\n'],\n",
       " ['blackassign0047',\n",
       "  'https://insights.blackcoffer.com/evolution-of-advertising-industry/\\n'],\n",
       " ['blackassign0048',\n",
       "  'https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/\\n'],\n",
       " ['blackassign0049',\n",
       "  'https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\\n'],\n",
       " ['blackassign0050',\n",
       "  'https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/\\n'],\n",
       " ['blackassign0051',\n",
       "  'https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/\\n'],\n",
       " ['blackassign0052',\n",
       "  'https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/\\n'],\n",
       " ['blackassign0053',\n",
       "  'https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/\\n'],\n",
       " ['blackassign0054',\n",
       "  'https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\\n'],\n",
       " ['blackassign0055',\n",
       "  'https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/\\n'],\n",
       " ['blackassign0056',\n",
       "  'https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/\\n'],\n",
       " ['blackassign0057',\n",
       "  'https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/\\n'],\n",
       " ['blackassign0058',\n",
       "  'https://insights.blackcoffer.com/how-we-forecast-future-technologies/\\n'],\n",
       " ['blackassign0059',\n",
       "  'https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\\n'],\n",
       " ['blackassign0060',\n",
       "  'https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/\\n'],\n",
       " ['blackassign0061',\n",
       "  'https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/\\n'],\n",
       " ['blackassign0062',\n",
       "  'https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/\\n'],\n",
       " ['blackassign0063',\n",
       "  'https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/\\n'],\n",
       " ['blackassign0064',\n",
       "  'https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\\n'],\n",
       " ['blackassign0065',\n",
       "  'https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/\\n'],\n",
       " ['blackassign0066',\n",
       "  'https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/\\n'],\n",
       " ['blackassign0067',\n",
       "  'https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/\\n'],\n",
       " ['blackassign0068',\n",
       "  'https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/\\n'],\n",
       " ['blackassign0069',\n",
       "  'https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/\\n'],\n",
       " ['blackassign0070',\n",
       "  'https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/\\n'],\n",
       " ['blackassign0071',\n",
       "  'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\\n'],\n",
       " ['blackassign0072',\n",
       "  'https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/\\n'],\n",
       " ['blackassign0073',\n",
       "  'https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/\\n'],\n",
       " ['blackassign0074',\n",
       "  'https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/\\n'],\n",
       " ['blackassign0075',\n",
       "  'https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/\\n'],\n",
       " ['blackassign0076',\n",
       "  'https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/\\n'],\n",
       " ['blackassign0077',\n",
       "  'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/\\n'],\n",
       " ['blackassign0078',\n",
       "  'https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/\\n'],\n",
       " ['blackassign0079',\n",
       "  'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/\\n'],\n",
       " ['blackassign0080',\n",
       "  'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/\\n'],\n",
       " ['blackassign0081',\n",
       "  'https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/\\n'],\n",
       " ['blackassign0082',\n",
       "  'https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/\\n'],\n",
       " ['blackassign0083',\n",
       "  'https://insights.blackcoffer.com/human-rights-outlook/\\n'],\n",
       " ['blackassign0084',\n",
       "  'https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\\n'],\n",
       " ['blackassign0085',\n",
       "  'https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/\\n'],\n",
       " ['blackassign0086',\n",
       "  'https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/\\n'],\n",
       " ['blackassign0087',\n",
       "  'https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/\\n'],\n",
       " ['blackassign0088',\n",
       "  'https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/\\n'],\n",
       " ['blackassign0089',\n",
       "  'https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/\\n'],\n",
       " ['blackassign0090',\n",
       "  'https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/\\n'],\n",
       " ['blackassign0091',\n",
       "  'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/\\n'],\n",
       " ['blackassign0092',\n",
       "  'https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/\\n'],\n",
       " ['blackassign0093',\n",
       "  'https://insights.blackcoffer.com/travel-and-tourism-outlook/\\n'],\n",
       " ['blackassign0094',\n",
       "  'https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/\\n'],\n",
       " ['blackassign0095',\n",
       "  'https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/\\n'],\n",
       " ['blackassign0096',\n",
       "  'https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/\\n'],\n",
       " ['blackassign0097',\n",
       "  'https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/\\n'],\n",
       " ['blackassign0098',\n",
       "  'https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/\\n'],\n",
       " ['blackassign0099',\n",
       "  'https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/\\n'],\n",
       " ['blackassign0100',\n",
       "  'https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n'],\n",
       " ['', '\\n']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[]\n",
    "with open(\"Input.csv\",\"r\") as f:\n",
    "    k=f.readline()\n",
    "    k=f.readline()\n",
    "    while k:\n",
    "        a.append(k.split(\",\"))\n",
    "        k=f.readline()\n",
    "a \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a[20:101]:\n",
    "    try:\n",
    "        r=requests.get(i[-1]).content\n",
    "        soup=BeautifulSoup(r,'html.parser')\n",
    "        heading=soup.find(\"h1\")\n",
    "        heading=heading.text.strip()\n",
    "        para=soup.find_all(class_=\"td-post-content\")\n",
    "        with open(f'resource/{i[0]}.txt','w') as f:\n",
    "            f.writelines(heading)\n",
    "            for i in para:\n",
    "                f.writelines(i.get_text(separator=\" \",strip=True))\n",
    "    except:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xef in position 28564: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m         positive_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines())\n\u001b[0;32m     10\u001b[0m positive_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mcorpus\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mwordlist\u001b[38;5;241m.\u001b[39mWordListCorpusReader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasterDictionary\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive-words.txt\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mwords())\n\u001b[1;32m---> 11\u001b[0m negative_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwordlist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWordListCorpusReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMasterDictionary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnegative-words.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     12\u001b[0m resource_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Path to the folder containing text files\u001b[39;00m\n\u001b[0;32m     13\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Desired output CSV file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\nltk\\corpus\\reader\\api.py:219\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(f) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m--> 219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\nltk\\data.py:1055\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;124;03m    Read up to ``size`` bytes, decode them using this reader's\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;124;03m    encoding, and return the resulting unicode string.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;124;03m    :rtype: unicode\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1055\u001b[0m     chars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# If linebuffer is not empty, then include it in the result\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinebuffer:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\nltk\\data.py:1344\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader._read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbytebuffer \u001b[38;5;241m+\u001b[39m new_bytes\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;66;03m# Decode the bytes into unicode characters\u001b[39;00m\n\u001b[1;32m-> 1344\u001b[0m chars, bytes_decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_incr_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;66;03m# If we got bytes but couldn't decode any, then read further.\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m chars) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(new_bytes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\nltk\\data.py:1375\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader._incr_decode\u001b[1;34m(self, bytes)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;66;03m# If the exception occurs at the end of the string,\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m         \u001b[38;5;66;03m# then assume that it's a truncation error.\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mend \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mbytes\u001b[39m):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\encodings\\utf_8.py:16\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xef in position 28564: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Step 1: Load required data and define paths\n",
    "stop_words = []\n",
    "for file in os.listdir(\"StopWords\"):\n",
    "    #with open(os.path.join(\"StopWords\", file), \"r\") as f:\n",
    "        #stop_words.extend(f.read().splitlines())\n",
    "    #with open(os.path.join(\"MasterDictionary\", \"positive-words.txt\"), \"r\", encoding=\"latin-1\") as f:\n",
    "        #positive_words = set(f.read().splitlines())\n",
    "    with open(os.path.join(\"MasterDictionary\", \"positive-words.txt\"), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        positive_words = set(f.read().splitlines())\n",
    "positive_words = set(nltk.corpus.reader.wordlist.WordListCorpusReader(\"MasterDictionary\", ['positive-words.txt']).words())\n",
    "negative_words = set(nltk.corpus.reader.wordlist.WordListCorpusReader(\"MasterDictionary\", ['negative-words.txt']).words())\n",
    "resource_folder = \"resource\"  # Path to the folder containing text files\n",
    "output_csv = \"output_data.csv\"  # Desired output CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text):\n",
    "    clean_text = preprocess_text(text)\n",
    "    tokens = word_tokenize(clean_text)\n",
    "    sentences = sent_tokenize(clean_text)\n",
    "\n",
    "    positive_score = sum(1 for word in tokens if word in positive_words and word not in stop_words)\n",
    "    negative_score = -1 * sum(1 for word in tokens if word in negative_words and word not in stop_words)\n",
    "    polarity_score = (positive_score - negative_score) / (positive_score + negative_score + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (len(tokens) + 0.000001)\n",
    "\n",
    "    average_sentence_length = len(tokens) / len(sentences)\n",
    "    percentage_complex_words = count_complex_words(tokens) / len(tokens)\n",
    "    fog_index = 0.4 * (average_sentence_length + percentage_complex_words)\n",
    "\n",
    "    average_words_per_sentence = len(tokens) / len(sentences)\n",
    "    complex_word_count = count_complex_words(tokens)\n",
    "    word_count = len(tokens)\n",
    "    syllable_per_word = count_syllables(tokens) / len(tokens)\n",
    "    personal_pronouns = count_personal_pronouns(clean_text)\n",
    "    average_word_length = sum(len(word) for word in tokens) / len(tokens)\n",
    "\n",
    "    return {\n",
    "        \"POSITIVE SCORE\": positive_score,\n",
    "        \"NEGATIVE SCORE\": negative_score,\n",
    "        \"POLARITY SCORE\": polarity_score,\n",
    "        \"SUBJECTIVITY SCORE\": subjectivity_score,\n",
    "        \"AVG SENTENCE LENGTH\": average_sentence_length,\n",
    "        \"PERCENTAGE OF COMPLEX WORDS\": percentage_complex_words,\n",
    "        \"FOG INDEX\": fog_index,\n",
    "        \"AVG NUMBER OF WORDS PER SENTENCE\": average_words_per_sentence,\n",
    "        \"COMPLEX WORD COUNT\": complex_word_count,\n",
    "        \"WORD COUNT\": word_count,\n",
    "        \"SYLLABLE PER WORD\": syllable_per_word,\n",
    "        \"PERSONAL PRONOUNS\": personal_pronouns,\n",
    "        \"AVG WORD LENGTH\": average_word_length\n",
    "    }\n",
    "\n",
    "def preprocess_text(text):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text.lower())\n",
    "\n",
    "def count_complex_words(tokens):\n",
    "    return sum(count_syllables(word) > 2 for word in tokens)\n",
    "\n",
    "def count_syllables(word):\n",
    "    count = 0\n",
    "    vowels = \"aeiouy\"\n",
    "    for i, char in enumerate(word):\n",
    "        if char in vowels:\n",
    "            count += 1\n",
    "            if i != 0 and word[i-1] not in vowels and char != \"e\":\n",
    "                count += 1\n",
    "    if word.endswith(\"es\") or word.endswith(\"ed\"):\n",
    "        count -= 1\n",
    "    return max(count, 1)\n",
    "\n",
    "def count_personal_pronouns(text):\n",
    "    pattern = r\"\\b(I|we|my|ours|us)\\b(?<!US)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file blackassign0001.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0002.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0003.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0004.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0005.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0006.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0007.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0008.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0009.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0010.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0011.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0012.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0013.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0014.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0015.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0016.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0017.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0018.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0019.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0021.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0022.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0023.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0024.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0025.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0026.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0027.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0028.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0029.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0030.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0031.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0032.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0033.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0034.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0035.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0037.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0038.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0039.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0040.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0041.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0042.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0043.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0044.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0045.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0046.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0047.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0048.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0050.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0051.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0052.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0053.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0054.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0055.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0056.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0057.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0058.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0059.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0060.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0061.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0062.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0063.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0064.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0065.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0066.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0067.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0068.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0069.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0070.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0071.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0072.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0073.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0074.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0075.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0076.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0077.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0078.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0079.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0080.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0081.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0082.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0083.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0084.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0085.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0086.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0087.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0088.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0089.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0090.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0091.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0092.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0093.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0094.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0095.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0096.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0097.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0098.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0099.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n",
      "Error processing file blackassign0100.txt: \n",
      "**********************************************************************\n",
      "  Resource \u001b[93mpunkt\u001b[0m not found.\n",
      "  Please use the NLTK Downloader to obtain the resource:\n",
      "\n",
      "  \u001b[31m>>> import nltk\n",
      "  >>> nltk.download('punkt')\n",
      "  \u001b[0m\n",
      "  For more information see: https://www.nltk.org/data.html\n",
      "\n",
      "  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n",
      "\n",
      "  Searched in:\n",
      "    - 'C:\\\\Users\\\\INDIA/nltk_data'\n",
      "    - 'c:\\\\Python311\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\share\\\\nltk_data'\n",
      "    - 'c:\\\\Python311\\\\lib\\\\nltk_data'\n",
      "    - 'C:\\\\Users\\\\INDIA\\\\AppData\\\\Roaming\\\\nltk_data'\n",
      "    - 'C:\\\\nltk_data'\n",
      "    - 'D:\\\\nltk_data'\n",
      "    - 'E:\\\\nltk_data'\n",
      "    - ''\n",
      "**********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_data = [] # List to store analysis results\n",
    "resource_folder = \"resource\" \n",
    "for filename in os.listdir(resource_folder):\n",
    "    if filename.endswith(\".txt\"):  # Ensure only text files are processed\n",
    "        text_file_path = os.path.join(resource_folder, filename)\n",
    "        url_id = filename.split(\".\")[0]  # Extract URL_ID from filename\n",
    "\n",
    "        try:\n",
    "            with open(text_file_path, \"r\") as f:\n",
    "                text = f.read()\n",
    "            result = analyze_text(text)\n",
    "            result[\"URL_ID\"] = url_id  # Add URL_ID to the results\n",
    "            output_data.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {filename}: {e}\")  # Improved error handling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create DataFrame and save as CSV\n",
    "output_df = pd.DataFrame(output_data)\n",
    "output_df.to_csv(output_csv, index=False)\n",
    "print(f\"Text analysis results saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
